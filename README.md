# [Kaggle - LLM 20 Questions](https://www.kaggle.com/competitions/llm-20-questions/overview)

This is a solution to the [LLM 20 Questions](https://www.kaggle.com/competitions/llm-20-questions/overview)
competion hostead on Kaggle.

The goal of the competition is to create autonomous agents that can play the
roles of `guesser` and `answerer` in a game of 20 questions.

In the game of 20 questions the `guesser` attempts to discover the secret word,
known only by the `answerer`, by asking at most 20 `yes/no` questions only.

## How to install and use
Clone the repository:
```
git clone
```

Install the package.
```
pip install
```

For development mode it is recommended to install the [flit](https://flit.pypa.io/en/stable/)
python packing tool and install the package in dev mode.
```
flit install --symlink --deps all
```

Get the [gemma-2b-it](https://ai.google.dev/gemma/docs/model_card_2), version 3,
LLM [huggingface](https://huggingface.co/google/gemma-2b-it) transformer weights
and put them in the root of the repository under `./gemma/models/transformers/2b-it/3/`.

Run `play20q` or `python llm20q/play.py` to play a game of 20 question between
to gemma based agents.

## Solution
### Answerer
The `answerer` replace keywords (e.g.: `it`, `secret word`) in the question the
secret word and than prompts an LLM ([gemma-2b-it](https://ai.google.dev/gemma/docs/model_card_2)) with the resulting question
to generate the `yes/no` response. The response is selected as the token with
the higest next token probability out of the 7 tokens that represent `yes/no`.
(The tokens differ in capitalization)

### Guesser
The `guesser` must generate question as well as guess words for every turn.

For question generation the `guesser` uses a handcrafted heuristic line of
questions to determine the broad category of the secret word. After the heuristic
questions are exhausted free-form questions are generated by prompting an LLM
([gemma-2b-it](https://ai.google.dev/gemma/docs/model_card_2)) with a
description of the secret word based on the previous questions answers as well
as the failed previous guesses. The LLM is prompted to name something that
matches the description. The generated tokens are used to create a question of
the from "Is it {generated_tokens}?".

For the guess generation the `guesser` use the same prompt strategy as for free
form question generation, the difference being made by the inclusion of the
question response at the current turn and that the generated tokens are used as
answers directly.
